{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idiom Vocab Helper \n",
    "\n",
    "This notebook creates a list of all the know idioms from the given MAGPIE dataset and creates Single-Tokens for them. This list of single-tokens will be inserted into the vocabulary of a LM using **model_download_add_tokensipynb**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TODO: Should I create a list of idioms from the entire data(combined training, dev & test sets)? Would it still be \n",
    "# called zero-shot if I do so?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_colwidth=500\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "root_dir = '../'\n",
    "base_dir = root_dir + 'data/magpie/'\n",
    "data_file = base_dir + 'MAGPIE_filtered_split_typebased.jsonl'\n",
    "\n",
    "output_token_dir = root_dir + 'data/token_files/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>context</th>\n",
       "      <th>document_id</th>\n",
       "      <th>genre</th>\n",
       "      <th>id</th>\n",
       "      <th>idiom</th>\n",
       "      <th>judgment_count</th>\n",
       "      <th>label</th>\n",
       "      <th>label_distribution</th>\n",
       "      <th>non_standard_usage_explanations</th>\n",
       "      <th>offsets</th>\n",
       "      <th>sentence_no</th>\n",
       "      <th>split</th>\n",
       "      <th>variant_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[Please , can we close the doggy postbag for now !, Remember that RUNNING is looking for all kinds of safety tips ., For example , with fell running and mountain marathons gaining in popularity , how about some ideas for safe running off the beaten track ?, FITNESS CLINIC, DIET]</td>\n",
       "      <td>AR7</td>\n",
       "      <td>W pop lore</td>\n",
       "      <td>0</td>\n",
       "      <td>off the beaten track</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[117, 120], [125, 131], [132, 137]]</td>\n",
       "      <td>626</td>\n",
       "      <td>training</td>\n",
       "      <td>identical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.770109</td>\n",
       "      <td>[But it 's a selfish family , I 'd say ., They take what they want ., I 'd keep him well in the running ., Then of course there 's Desmond 's wife — I 'd forgotten her ., I did n't get much of an impression of her .]</td>\n",
       "      <td>H9D</td>\n",
       "      <td>W fict prose</td>\n",
       "      <td>1</td>\n",
       "      <td>in the running</td>\n",
       "      <td>10</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 0.770109357701371, 'l': 0.22989064229862802, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[19, 21], [26, 33]]</td>\n",
       "      <td>1520</td>\n",
       "      <td>training</td>\n",
       "      <td>identical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[And I looked behind , and he was just sitting there staring like that ., Oh my god ., He gives me the creeps , so I looked round , hmm hmm ., I mean , what is she doing ?, What does she want ?]</td>\n",
       "      <td>KNY</td>\n",
       "      <td>S conv</td>\n",
       "      <td>2</td>\n",
       "      <td>give someone the creeps</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[3, 8], [9, 11], [16, 22]]</td>\n",
       "      <td>1850</td>\n",
       "      <td>training</td>\n",
       "      <td>combined-inflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[Especially this year ., Makes me hair stand on end just thinking about it.’, ‘ He 's done us proud , as well,’ says Granville ., ‘ He had the chance to go to the States with them but he said , ‘ No’ ., Other commitments.’]</td>\n",
       "      <td>CK4</td>\n",
       "      <td>W pop lore</td>\n",
       "      <td>3</td>\n",
       "      <td>do someone proud</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[8, 12], [13, 15], [16, 21]]</td>\n",
       "      <td>613</td>\n",
       "      <td>training</td>\n",
       "      <td>combined-inflection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[Rather , what is needed most is a new way of thinking – new “ software ” ( though effective “ hard ” green technologies also are essential ) ., As we saw in the postcommunist world , changing attitudes is often the hardest problem of all ., People quickly embraced formal democracy , but the tolerance and compromise that is at the heart of the democratic process took time to take root ., , ]</td>\n",
       "      <td>p63d3559</td>\n",
       "      <td>PMB</td>\n",
       "      <td>4</td>\n",
       "      <td>take root</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[136, 140], [141, 145]]</td>\n",
       "      <td>15</td>\n",
       "      <td>training</td>\n",
       "      <td>identical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48390</th>\n",
       "      <td>0.854973</td>\n",
       "      <td>[The running of multiple sessions has been another means of saving which , though not always a problem , has led to truncated teaching sessions , late - coming and absenteeism on the part of teachers and pupils ., Teacher absenteeism is also exacerbated by general shortages of goods and services : teachers , like other employees , can spend half their days chasing scarce consumer goods for their families , instead of being in the classroom ., Many also have second or third jobs to make ends ...</td>\n",
       "      <td>B12</td>\n",
       "      <td>W ac:polit law edu</td>\n",
       "      <td>48390</td>\n",
       "      <td>make ends meet</td>\n",
       "      <td>9</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 0.8549734944978761, 'l': 0.145026505502123, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[39, 43], [44, 48], [49, 53]]</td>\n",
       "      <td>246</td>\n",
       "      <td>test</td>\n",
       "      <td>identical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48391</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[you understand the process ?, Yeah , yeah, Take people to objections , take them to where you want them to be and bear in mind you 're always looking for an objection, Yeah, right , another thing , we wanna get more quotes , right]</td>\n",
       "      <td>KDJ</td>\n",
       "      <td>S conv</td>\n",
       "      <td>48391</td>\n",
       "      <td>bear in mind</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[71, 75], [76, 78], [79, 83]]</td>\n",
       "      <td>207</td>\n",
       "      <td>training</td>\n",
       "      <td>identical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48392</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[The same implications attach to the playing of games or the membership of clubs and so on , although what is of even more interest are the ' unwritten ' rules which underwrite the more formal , quasi - legal , ones ., Without unwritten rules civilised life would be impossible ., Indeed we are rarely aware of them as rules , until they are broken , since they are typical of the settings in which we received our moral training ., Many were originally instinctive and , to that limited extent ,...</td>\n",
       "      <td>CM8</td>\n",
       "      <td>W ac:humanities arts</td>\n",
       "      <td>48392</td>\n",
       "      <td>as a rule</td>\n",
       "      <td>4</td>\n",
       "      <td>l</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 0.0, 'l': 1.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[35, 37], [38, 43]]</td>\n",
       "      <td>865</td>\n",
       "      <td>training</td>\n",
       "      <td>deletion-determiner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48393</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[A manufacturer can work closely with its suppliers , co - operating on the development of new components , for instance ., It is like being part of the same company , but without the drawbacks ., Unlike in a firm that is a jack of all trades , the supplier is an independent business subject to market disciplines rather than another bit of a big bureaucracy ., From the supplier 's point of view , the relationship is better than simply one based on contracts , price and open bidding ., Though...</td>\n",
       "      <td>ABJ</td>\n",
       "      <td>W pop lore</td>\n",
       "      <td>48393</td>\n",
       "      <td>jack of all trades</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[27, 31], [32, 34], [35, 38], [39, 45]]</td>\n",
       "      <td>4073</td>\n",
       "      <td>training</td>\n",
       "      <td>identical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48394</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>[That 's optimistic ., The announcement that National Insurance rates are to stay the same is more window - dressing , I think ., The Government flies these kites of disinformation then people feel grateful when they do n't happen ., The Chancellor has shifted a few factors around , that 's all ., Brilliant Brown goes for the jugular]</td>\n",
       "      <td>CEK</td>\n",
       "      <td>W newsp other: social</td>\n",
       "      <td>48394</td>\n",
       "      <td>fly a kite</td>\n",
       "      <td>3</td>\n",
       "      <td>i</td>\n",
       "      <td>{'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[15, 20], [27, 32]]</td>\n",
       "      <td>5616</td>\n",
       "      <td>training</td>\n",
       "      <td>combined-inflection</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48395 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       confidence  \\\n",
       "0        1.000000   \n",
       "1        0.770109   \n",
       "2        1.000000   \n",
       "3        1.000000   \n",
       "4        1.000000   \n",
       "...           ...   \n",
       "48390    0.854973   \n",
       "48391    1.000000   \n",
       "48392    1.000000   \n",
       "48393    1.000000   \n",
       "48394    1.000000   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   context  \\\n",
       "0                                                                                                                                                                                                                                  [Please , can we close the doggy postbag for now !, Remember that RUNNING is looking for all kinds of safety tips ., For example , with fell running and mountain marathons gaining in popularity , how about some ideas for safe running off the beaten track ?, FITNESS CLINIC, DIET]   \n",
       "1                                                                                                                                                                                                                                                                                                 [But it 's a selfish family , I 'd say ., They take what they want ., I 'd keep him well in the running ., Then of course there 's Desmond 's wife — I 'd forgotten her ., I did n't get much of an impression of her .]   \n",
       "2                                                                                                                                                                                                                                                                                                                       [And I looked behind , and he was just sitting there staring like that ., Oh my god ., He gives me the creeps , so I looked round , hmm hmm ., I mean , what is she doing ?, What does she want ?]   \n",
       "3                                                                                                                                                                                                                                                                                          [Especially this year ., Makes me hair stand on end just thinking about it.’, ‘ He 's done us proud , as well,’ says Granville ., ‘ He had the chance to go to the States with them but he said , ‘ No’ ., Other commitments.’]   \n",
       "4                                                                                                               [Rather , what is needed most is a new way of thinking – new “ software ” ( though effective “ hard ” green technologies also are essential ) ., As we saw in the postcommunist world , changing attitudes is often the hardest problem of all ., People quickly embraced formal democracy , but the tolerance and compromise that is at the heart of the democratic process took time to take root ., , ]   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ...   \n",
       "48390  [The running of multiple sessions has been another means of saving which , though not always a problem , has led to truncated teaching sessions , late - coming and absenteeism on the part of teachers and pupils ., Teacher absenteeism is also exacerbated by general shortages of goods and services : teachers , like other employees , can spend half their days chasing scarce consumer goods for their families , instead of being in the classroom ., Many also have second or third jobs to make ends ...   \n",
       "48391                                                                                                                                                                                                                                                                             [you understand the process ?, Yeah , yeah, Take people to objections , take them to where you want them to be and bear in mind you 're always looking for an objection, Yeah, right , another thing , we wanna get more quotes , right]   \n",
       "48392  [The same implications attach to the playing of games or the membership of clubs and so on , although what is of even more interest are the ' unwritten ' rules which underwrite the more formal , quasi - legal , ones ., Without unwritten rules civilised life would be impossible ., Indeed we are rarely aware of them as rules , until they are broken , since they are typical of the settings in which we received our moral training ., Many were originally instinctive and , to that limited extent ,...   \n",
       "48393  [A manufacturer can work closely with its suppliers , co - operating on the development of new components , for instance ., It is like being part of the same company , but without the drawbacks ., Unlike in a firm that is a jack of all trades , the supplier is an independent business subject to market disciplines rather than another bit of a big bureaucracy ., From the supplier 's point of view , the relationship is better than simply one based on contracts , price and open bidding ., Though...   \n",
       "48394                                                                                                                                                                     [That 's optimistic ., The announcement that National Insurance rates are to stay the same is more window - dressing , I think ., The Government flies these kites of disinformation then people feel grateful when they do n't happen ., The Chancellor has shifted a few factors around , that 's all ., Brilliant Brown goes for the jugular]   \n",
       "\n",
       "      document_id                  genre     id                    idiom  \\\n",
       "0             AR7             W pop lore      0     off the beaten track   \n",
       "1             H9D           W fict prose      1           in the running   \n",
       "2             KNY                 S conv      2  give someone the creeps   \n",
       "3             CK4             W pop lore      3         do someone proud   \n",
       "4        p63d3559                    PMB      4                take root   \n",
       "...           ...                    ...    ...                      ...   \n",
       "48390         B12     W ac:polit law edu  48390           make ends meet   \n",
       "48391         KDJ                 S conv  48391             bear in mind   \n",
       "48392         CM8   W ac:humanities arts  48392                as a rule   \n",
       "48393         ABJ             W pop lore  48393       jack of all trades   \n",
       "48394         CEK  W newsp other: social  48394               fly a kite   \n",
       "\n",
       "       judgment_count label  \\\n",
       "0                   3     i   \n",
       "1                  10     i   \n",
       "2                   3     i   \n",
       "3                   3     i   \n",
       "4                   3     i   \n",
       "...               ...   ...   \n",
       "48390               9     i   \n",
       "48391               3     i   \n",
       "48392               4     l   \n",
       "48393               3     i   \n",
       "48394               3     i   \n",
       "\n",
       "                                                                     label_distribution  \\\n",
       "0                                    {'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}   \n",
       "1      {'?': 0.0, 'f': 0.0, 'i': 0.770109357701371, 'l': 0.22989064229862802, 'o': 0.0}   \n",
       "2                                    {'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}   \n",
       "3                                    {'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}   \n",
       "4                                    {'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}   \n",
       "...                                                                                 ...   \n",
       "48390   {'?': 0.0, 'f': 0.0, 'i': 0.8549734944978761, 'l': 0.145026505502123, 'o': 0.0}   \n",
       "48391                                {'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}   \n",
       "48392                                {'?': 0.0, 'f': 0.0, 'i': 0.0, 'l': 1.0, 'o': 0.0}   \n",
       "48393                                {'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}   \n",
       "48394                                {'?': 0.0, 'f': 0.0, 'i': 1.0, 'l': 0.0, 'o': 0.0}   \n",
       "\n",
       "      non_standard_usage_explanations  \\\n",
       "0                                  []   \n",
       "1                                  []   \n",
       "2                                  []   \n",
       "3                                  []   \n",
       "4                                  []   \n",
       "...                               ...   \n",
       "48390                              []   \n",
       "48391                              []   \n",
       "48392                              []   \n",
       "48393                              []   \n",
       "48394                              []   \n",
       "\n",
       "                                        offsets  sentence_no     split  \\\n",
       "0          [[117, 120], [125, 131], [132, 137]]          626  training   \n",
       "1                          [[19, 21], [26, 33]]         1520  training   \n",
       "2                   [[3, 8], [9, 11], [16, 22]]         1850  training   \n",
       "3                 [[8, 12], [13, 15], [16, 21]]          613  training   \n",
       "4                      [[136, 140], [141, 145]]           15  training   \n",
       "...                                         ...          ...       ...   \n",
       "48390            [[39, 43], [44, 48], [49, 53]]          246      test   \n",
       "48391            [[71, 75], [76, 78], [79, 83]]          207  training   \n",
       "48392                      [[35, 37], [38, 43]]          865  training   \n",
       "48393  [[27, 31], [32, 34], [35, 38], [39, 45]]         4073  training   \n",
       "48394                      [[15, 20], [27, 32]]         5616  training   \n",
       "\n",
       "              variant_type  \n",
       "0                identical  \n",
       "1                identical  \n",
       "2      combined-inflection  \n",
       "3      combined-inflection  \n",
       "4                identical  \n",
       "...                    ...  \n",
       "48390            identical  \n",
       "48391            identical  \n",
       "48392  deletion-determiner  \n",
       "48393            identical  \n",
       "48394  combined-inflection  \n",
       "\n",
       "[48395 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_json(data_file, lines=True)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOTE: Considering the entire data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           off the beaten track\n",
       "1                 in the running\n",
       "2        give someone the creeps\n",
       "3               do someone proud\n",
       "4                      take root\n",
       "                  ...           \n",
       "48390             make ends meet\n",
       "48391               bear in mind\n",
       "48392                  as a rule\n",
       "48393         jack of all trades\n",
       "48394                 fly a kite\n",
       "Name: idiom, Length: 48395, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['idiom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     25308\n",
       "False    23087\n",
       "Name: idiom_exact_match, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if the values in 'idiom' column are used exactly as it is in the sentece\n",
    "df_data['idiom_exact_match'] = df_data.apply(lambda row: row['idiom'] in row['context'][2], axis=1)\n",
    "df_data['idiom_exact_match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>idiom_exact_match</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">i</th>\n",
       "      <th>True</th>\n",
       "      <td>21124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>15204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">l</th>\n",
       "      <th>False</th>\n",
       "      <td>7883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>4184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0\n",
       "label idiom_exact_match       \n",
       "i     True               21124\n",
       "      False              15204\n",
       "l     False               7883\n",
       "      True                4184"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = df_data[[ 'label', 'idiom_exact_match']].value_counts()\n",
    "pd.DataFrame(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string\n",
    "trans = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def idiom_to_token(idiom_phrase):\n",
    "    \"\"\"Process the given idiom phrase and convert into a string token\"\"\"\n",
    "    idiom_phrase = idiom_phrase.translate(trans)\n",
    "    idiom_phrase = idiom_phrase.lower().replace(' ', '').lstrip().rstrip()\n",
    "    return '<BERTRAM:ID' + idiom_phrase + 'ID>' # for betram embeddings\n",
    "#     return 'ID' + idiom_phrase + 'ID'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Idioms are not matching exactly\n",
    "How to deal with ~50% of the examples where the value of the column 'idiom' is not matching exactly with that of its usage in the sentence?\n",
    "\n",
    "**Option-1**\n",
    "Just convert the values in 'idiom' column to tokens, irrespective of how they are used in the sentence. In other words, this approach will make the LM model to learn only those tokens which have an exact match. This leads to incomplete experiment, because we will capture only 50% of MWEs as single tokens.\n",
    "\n",
    "**Option-2**\n",
    "Use the **offsets** column and extract the actual MWE from the sentence. This will capture all possible MWEs in the data, but the number of unique tokens would be very high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "in the long run         200\n",
       "come to terms with      174\n",
       "with a view to          173\n",
       "bear in mind            172\n",
       "for the time being      171\n",
       "                       ... \n",
       "kill the fatted calf      1\n",
       "bum steer                 1\n",
       "bedroom eyes              1\n",
       "tickle the ivories        1\n",
       "them's the breaks         1\n",
       "Name: idiom, Length: 1738, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1738"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(df_data['idiom'].value_counts())\n",
    "df_data['idiom'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idiom</th>\n",
       "      <th>idiom_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10692</th>\n",
       "      <td>by hook or by crook</td>\n",
       "      <td>&lt;BERTRAM:IDbyhookorbycrookID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44666</th>\n",
       "      <td>one of those things</td>\n",
       "      <td>&lt;BERTRAM:IDoneofthosethingsID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21632</th>\n",
       "      <td>turn heads</td>\n",
       "      <td>&lt;BERTRAM:IDturnheadsID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10718</th>\n",
       "      <td>full tilt</td>\n",
       "      <td>&lt;BERTRAM:IDfulltiltID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7923</th>\n",
       "      <td>under fire</td>\n",
       "      <td>&lt;BERTRAM:IDunderfireID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15391</th>\n",
       "      <td>go it alone</td>\n",
       "      <td>&lt;BERTRAM:IDgoitaloneID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33360</th>\n",
       "      <td>in the final analysis</td>\n",
       "      <td>&lt;BERTRAM:IDinthefinalanalysisID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33019</th>\n",
       "      <td>steer clear of</td>\n",
       "      <td>&lt;BERTRAM:IDsteerclearofID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41547</th>\n",
       "      <td>keep someone posted</td>\n",
       "      <td>&lt;BERTRAM:IDkeepsomeonepostedID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42236</th>\n",
       "      <td>separate the sheep from the goats</td>\n",
       "      <td>&lt;BERTRAM:IDseparatethesheepfromthegoatsID&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   idiom  \\\n",
       "10692                by hook or by crook   \n",
       "44666                one of those things   \n",
       "21632                         turn heads   \n",
       "10718                          full tilt   \n",
       "7923                          under fire   \n",
       "15391                        go it alone   \n",
       "33360              in the final analysis   \n",
       "33019                     steer clear of   \n",
       "41547                keep someone posted   \n",
       "42236  separate the sheep from the goats   \n",
       "\n",
       "                                      idiom_token  \n",
       "10692               <BERTRAM:IDbyhookorbycrookID>  \n",
       "44666              <BERTRAM:IDoneofthosethingsID>  \n",
       "21632                     <BERTRAM:IDturnheadsID>  \n",
       "10718                      <BERTRAM:IDfulltiltID>  \n",
       "7923                      <BERTRAM:IDunderfireID>  \n",
       "15391                     <BERTRAM:IDgoitaloneID>  \n",
       "33360            <BERTRAM:IDinthefinalanalysisID>  \n",
       "33019                  <BERTRAM:IDsteerclearofID>  \n",
       "41547             <BERTRAM:IDkeepsomeonepostedID>  \n",
       "42236  <BERTRAM:IDseparatethesheepfromthegoatsID>  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['idiom_token'] = df_data['idiom'].map(idiom_to_token)\n",
    "df_data[['idiom', 'idiom_token']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the 1738 tokens to ../data/token_files/option1_idiom_tokens_bertram.txt\n"
     ]
    }
   ],
   "source": [
    "# Save the list of idioms\n",
    "option_1_idiom_token_file = output_token_dir + 'option1_idiom_tokens.txt'\n",
    "bertram_option_1_idiom_token_file = output_token_dir + 'option1_idiom_tokens_bertram.txt'\n",
    "\n",
    "unique_tokens = df_data['idiom_token'].unique()\n",
    "np.savetxt(bertram_option_1_idiom_token_file, unique_tokens, fmt='%s', header='')\n",
    "print(f'Saved the {unique_tokens.shape[0]} tokens to {bertram_option_1_idiom_token_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the <idiom,token> pairs to ../data/token_files/option1_idioms_bertram.csv\n"
     ]
    }
   ],
   "source": [
    "# Save both idiom and its token; to be used for replacing the idioms in datasets\n",
    "option_1_idioms_file = output_token_dir + 'option1_idioms.csv'\n",
    "bertram_option_1_idioms_file = output_token_dir + 'option1_idioms_bertram.csv'\n",
    "\n",
    "df_idioms = df_data[['idiom', 'idiom_token']].drop_duplicates(subset='idiom_token', keep=\"first\")\n",
    "df_idioms.to_csv(bertram_option_1_idioms_file, index=False)\n",
    "print(f'Saved the <idiom,token> pairs to {bertram_option_1_idioms_file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_idiom_phrase(row):\n",
    "    sentence = row['context'][2]\n",
    "    # Pair of start and end positions of an MWE within the sentence\n",
    "    offsets = row['offsets']\n",
    "    # Being crude here, so that the exact usage of the MWE is captured\n",
    "    start = offsets[0][0] # Start of the first word\n",
    "    end = offsets[-1][1] # End of the last word\n",
    "    return sentence[start:end]\n",
    "# Extract the MWE from sentences\n",
    "df_data['idiom_phrase'] = df_data.apply(lambda row: extract_idiom_phrase(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idiom</th>\n",
       "      <th>idiom_phrase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10031</th>\n",
       "      <td>by heart</td>\n",
       "      <td>by heart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4802</th>\n",
       "      <td>get to grips with</td>\n",
       "      <td>gets to grips with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38898</th>\n",
       "      <td>with a will</td>\n",
       "      <td>with a will</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40274</th>\n",
       "      <td>on paper</td>\n",
       "      <td>on this paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12787</th>\n",
       "      <td>on the rocks</td>\n",
       "      <td>on the rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24827</th>\n",
       "      <td>out to lunch</td>\n",
       "      <td>out to lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5808</th>\n",
       "      <td>know the score</td>\n",
       "      <td>know the score.’</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34302</th>\n",
       "      <td>on paper</td>\n",
       "      <td>on the first paper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23880</th>\n",
       "      <td>foot the bill</td>\n",
       "      <td>footing the bill</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32177</th>\n",
       "      <td>fly in the face of</td>\n",
       "      <td>flying in the face of</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    idiom           idiom_phrase\n",
       "10031            by heart               by heart\n",
       "4802    get to grips with     gets to grips with\n",
       "38898         with a will            with a will\n",
       "40274            on paper          on this paper\n",
       "12787        on the rocks            on the rock\n",
       "24827        out to lunch           out to lunch\n",
       "5808       know the score       know the score.’\n",
       "34302            on paper     on the first paper\n",
       "23880       foot the bill       footing the bill\n",
       "32177  fly in the face of  flying in the face of"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data[['idiom', 'idiom_phrase']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idiom_phrase</th>\n",
       "      <th>idiom_phrase_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14765</th>\n",
       "      <td>far and away</td>\n",
       "      <td>&lt;BERTRAM:IDfarandawayID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27036</th>\n",
       "      <td>all and sundry</td>\n",
       "      <td>&lt;BERTRAM:IDallandsundryID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33590</th>\n",
       "      <td>come to think of it</td>\n",
       "      <td>&lt;BERTRAM:IDcometothinkofitID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8539</th>\n",
       "      <td>in the fog</td>\n",
       "      <td>&lt;BERTRAM:IDinthefogID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21016</th>\n",
       "      <td>hands down</td>\n",
       "      <td>&lt;BERTRAM:IDhandsdownID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35274</th>\n",
       "      <td>down the road</td>\n",
       "      <td>&lt;BERTRAM:IDdowntheroadID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41699</th>\n",
       "      <td>got a life</td>\n",
       "      <td>&lt;BERTRAM:IDgotalifeID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21314</th>\n",
       "      <td>bells and whistles’</td>\n",
       "      <td>&lt;BERTRAM:IDbellsandwhistles’ID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9926</th>\n",
       "      <td>cut loose</td>\n",
       "      <td>&lt;BERTRAM:IDcutlooseID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20708</th>\n",
       "      <td>on that level</td>\n",
       "      <td>&lt;BERTRAM:IDonthatlevelID&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              idiom_phrase               idiom_phrase_token\n",
       "14765         far and away         <BERTRAM:IDfarandawayID>\n",
       "27036       all and sundry       <BERTRAM:IDallandsundryID>\n",
       "33590  come to think of it    <BERTRAM:IDcometothinkofitID>\n",
       "8539            in the fog           <BERTRAM:IDinthefogID>\n",
       "21016           hands down          <BERTRAM:IDhandsdownID>\n",
       "35274        down the road        <BERTRAM:IDdowntheroadID>\n",
       "41699           got a life           <BERTRAM:IDgotalifeID>\n",
       "21314  bells and whistles’  <BERTRAM:IDbellsandwhistles’ID>\n",
       "9926             cut loose           <BERTRAM:IDcutlooseID>\n",
       "20708        on that level        <BERTRAM:IDonthatlevelID>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data['idiom_phrase_token'] = df_data['idiom_phrase'].map(idiom_to_token)\n",
    "df_data[['idiom_phrase', 'idiom_phrase_token']].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the 10871 tokens to ../data/token_files/option2_idiom_tokens_bertram.txt\n"
     ]
    }
   ],
   "source": [
    "# Save the list of idioms\n",
    "option_2_idiom_token_file = output_token_dir + 'option2_idiom_tokens.txt'\n",
    "bertram_option_2_idiom_token_file = output_token_dir + 'option2_idiom_tokens_bertram.txt'\n",
    "\n",
    "unique_tokens = df_data['idiom_phrase_token'].unique()\n",
    "np.savetxt(bertram_option_2_idiom_token_file, unique_tokens, fmt='%s', header='')\n",
    "print(f'Saved the {unique_tokens.shape[0]} tokens to {bertram_option_2_idiom_token_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idiom</th>\n",
       "      <th>idiom_token</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>off the beaten track</td>\n",
       "      <td>&lt;BERTRAM:IDoffthebeatentrackID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>in the running</td>\n",
       "      <td>&lt;BERTRAM:IDintherunningID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gives me the creeps</td>\n",
       "      <td>&lt;BERTRAM:IDgivesmethecreepsID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>done us proud</td>\n",
       "      <td>&lt;BERTRAM:IDdoneusproudID&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>take root</td>\n",
       "      <td>&lt;BERTRAM:IDtakerootID&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  idiom                      idiom_token\n",
       "0  off the beaten track  <BERTRAM:IDoffthebeatentrackID>\n",
       "1        in the running       <BERTRAM:IDintherunningID>\n",
       "2   gives me the creeps   <BERTRAM:IDgivesmethecreepsID>\n",
       "3         done us proud        <BERTRAM:IDdoneusproudID>\n",
       "4             take root           <BERTRAM:IDtakerootID>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns, to keep it consistent\n",
    "df_data = df_data[['idiom_phrase', 'idiom_phrase_token']]\n",
    "df_data = df_data.rename(columns={'idiom_phrase':'idiom', 'idiom_phrase_token':'idiom_token'})\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved the <idiom,token> pairs to ../data/token_files/option2_idioms_bertram.csv\n"
     ]
    }
   ],
   "source": [
    "# Save both idiom phrase and its token; to be used for replacing the idioms in datasets\n",
    "option_2_idioms_file = output_token_dir + 'option2_idioms.csv'\n",
    "bertram_option_2_idioms_file = output_token_dir + 'option2_idioms_bertram.csv'\n",
    "\n",
    "df_idioms = df_data[['idiom', 'idiom_token']].drop_duplicates(subset='idiom_token', keep=\"first\")\n",
    "df_idioms.to_csv(bertram_option_2_idioms_file, index=False)\n",
    "print(f'Saved the <idiom,token> pairs to {bertram_option_2_idioms_file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "acp20mym-idiomprinciple",
   "language": "python",
   "name": "acp20mym-idiomprinciple"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
